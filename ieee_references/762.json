[{"_id":7625741,"references":[{"order":"1","text":"L. J. Climini, \"Analysis and simulation of digital Mobile channel using Orthogonal Frequency division Multiplexing\", <em>IEEE Trans. Commun.</em>, vol. 33, no. 7, pp. 665-675, Jul. 1985.","title":"Analysis and simulation of digital Mobile channel using Orthogonal Frequency division Multiplexing","context":[{"sec":"sec1","text":"Orthogonal frequency division multiplexing (OFDM) has many applications in wireless communications [1]\u2013[3], and increasingly being deployed in broadband wireless communication standards such IEEE 802.11 Wi-Fi and IEEE 802.16WiMax.","part":"1"}],"links":{"documentLink":"/document/1096357","pdfSize":"1063KB"},"refType":"biblio","id":"ref1"},{"order":"2","text":"D. Nogulic, M. Gadze and A. Jankovic, \"Multicarrier modulation in advanced wireless communication systems\", <em>Proc. of 48th International Symposium ELMAR-2006</em>, pp. 175-179, Jun. 2006.","title":"Multicarrier modulation in advanced wireless communication systems","context":[{"sec":"sec1","text":"Orthogonal frequency division multiplexing (OFDM) has many applications in wireless communications [1]\u2013[2][3], and increasingly being deployed in broadband wireless communication standards such IEEE 802.11 Wi-Fi and IEEE 802.16WiMax.","part":"1"}],"links":{"documentLink":"/document/4127516","pdfSize":"5543KB"},"refType":"biblio","id":"ref2"},{"order":"3","text":"T. Hwang, C. Yang, G. Wu, S. Li and G. Y. Li, \"OFDM and itswireless applications: A survey\", <em>IEEE Trans. Veh. Technol.</em>, vol. 58, no. 4, pp. 1673-1694, May 2009.","title":"OFDM and itswireless applications: A survey","context":[{"sec":"sec1","text":"Orthogonal frequency division multiplexing (OFDM) has many applications in wireless communications [1]\u2013[3], and increasingly being deployed in broadband wireless communication standards such IEEE 802.11 Wi-Fi and IEEE 802.16WiMax.","part":"1"}],"links":{"documentLink":"/document/4607239","pdfSize":"688KB"},"refType":"biblio","id":"ref3"},{"order":"4","text":"A.N. Andrea, V. Lottici and R. Reggiannini, \"RF power amplifier linearization through amplitude and phase predistortion\", <em>IEEE Trans.Communications</em>, vol. 44, no. 11, pp. 1477-1484, 1997.","title":"RF power amplifier linearization through amplitude and phase predistortion","context":[{"sec":"sec1","text":" To improve linear region we use digital predistortion techniques [4]\u2013[6] which is one of the most cost effective.","part":"1"}],"links":{"documentLink":"/document/544464","pdfSize":"873KB"},"refType":"biblio","id":"ref4"},{"order":"5","text":"Ding Lei and G.T. Zhou, \"Effects of even-order nonlinear terms on power amplifier modeling and predistortion linearization\", <em>IEEE Trans. Vehicular Technology</em>, vol. 53, no. 1, pp. 156-162.","title":"Effects of even-order nonlinear terms on power amplifier modeling and predistortion linearization","context":[{"sec":"sec1","text":" To improve linear region we use digital predistortion techniques [4]\u2013[5][6] which is one of the most cost effective.","part":"1"}],"refType":"biblio","id":"ref5"},{"order":"6","text":"S. Andreoli, H.G. McClure, P. Banelli and S. Cacopardi, \"Digital linearizer for RF amplifiers\", <em>IEEE Trans.Broadcasting</em>, vol. 43, no. 1, pp. 12-19, 1997.","title":"Digital linearizer for RF amplifiers","context":[{"sec":"sec1","text":" To improve linear region we use digital predistortion techniques [4]\u2013[6] which is one of the most cost effective.","part":"1"}],"links":{"documentLink":"/document/566819","pdfSize":"841KB"},"refType":"biblio","id":"ref6"},{"order":"7","text":"C. Rapp, \"Effects of HPA-Nonlinearity on a 4-DPSK/OFDM-Signal for a Digitial Sound Broadcasting System\", <em>Proceedings of the Second European Conference on Satellite Communications</em>, vol. 2, pp. 179-184, 22 - 24 Oct. 1991.","title":"Effects of HPA-Nonlinearity on a 4-DPSK/OFDM-Signal for a Digitial Sound Broadcasting System","context":[{"sec":"sec1","text":" The Rapp model [7] is suitable for the nonlinear characteristic of State Power Amplifier (SSPA).","part":"1"}],"refType":"biblio","id":"ref7"},{"order":"8","text":"S. P. Stapleton and C. Costescu, \"An adaptive predistorter for a power amplifier based on adjacent channel emissions\", <em>IEEE Trans. Veh.Technol.</em>, vol. 41, pp. 49-56, Feb. 1992.","title":"An adaptive predistorter for a power amplifier based on adjacent channel emissions","context":[{"sec":"sec1","text":"In conventional method [8]\u2013[9], considering only the odd-order items on the system.","part":"1"}],"links":{"documentLink":"/document/120144","pdfSize":"727KB"},"refType":"biblio","id":"ref8"},{"order":"9","text":"E. Westesson and L. Sundstrom, \"A complex polynomial predistorter chip in CMOS for baseband or IF linearization of RF power amplifiers\", <em>Proc. IEEE Int. Symp. Circuits Syst.</em>, pp. 206-209, May 1999.","title":"A complex polynomial predistorter chip in CMOS for baseband or IF linearization of RF power amplifiers","context":[{"sec":"sec1","text":"In conventional method [8]\u2013[9], considering only the odd-order items on the system.","part":"1"}],"links":{"pdfSize":"413KB"},"refType":"biblio","id":"ref9"},{"order":"10","text":"J. Kim and K. Konstantinou, \"Digital predistortion of wideband signals based on power amplifier model with memory\", <em>Electron. Lett.</em>, vol. 37, no. 23, pp. 1417-1418, 2001.","title":"Digital predistortion of wideband signals based on power amplifier model with memory","context":[{"sec":"sec1","text":" In[10], Kim and Konstantinou where the first to consider including even-order terms in HPA models.","part":"1"}],"links":{"crossRefLink":"https://doi.org/10.1049/el:20010940","pdfSize":"248KB"},"refType":"biblio","id":"ref10"},{"order":"11","text":"Ding. Lei and G.T Zhou, \"Effects of even-order nonlinear terms on power amplifiermodeling and predistortion linearization\", <em>IEEE Trans. Veh.Technol.</em>, vol. 53, pp. 156-162, 2004.","title":"Effects of even-order nonlinear terms on power amplifiermodeling and predistortion linearization","context":[{"sec":"sec1","text":" In[11], Ding Lei were added in the even-order memory model and memoryless model are analyzed.","part":"1"}],"refType":"biblio","id":"ref11"}],"articleNumber":"7625741","issueLink":"/xpl/tocresult.jsp?isnumber=null","formulaStrippedArticleTitle":"Even-Order nonlinear correction of digital predistortion with maximum power amplification efficiency","publisher":"IEEE","displayDocTitle":"Even-Order nonlinear correction of digital predistortion with maximum power amplification efficiency","htmlAbstractLink":"/document/7625741/","isConference":true,"isStaticHtml":true,"htmlLink":"/document/7625741/","xploreDocumentType":"Conference Publication","isDynamicHtml":true,"articleId":"7625741","openAccessFlag":"F","title":"Even-Order nonlinear correction of digital predistortion with maximum power amplification efficiency","contentTypeDisplay":"Conferences","mlTime":"PT0.107166S","lastupdate":"2021-12-11","contentType":"conferences","definitions":"false","publicationNumber":"7589475"},{"_id":7625742,"references":[{"order":"1","text":"A.R. Sarkar, G Sanyal and S Majumder, \"Hand gesture recognition systems: a survey\", <em>International Journal of Computer Applications</em>, vol. 71, no. 15, pp. 0975-8887, May 2013.","title":"Hand gesture recognition systems: a survey","context":[{"sec":"sec1","text":" [1], the approaches using machine learning algorithms are very effective and high accurate, but they require comparatively highly computation time.","part":"1"}],"refType":"biblio","id":"ref1"},{"order":"2","text":"Zhou Ren, Junsong Yuan, Jingjing Meng and Zhengyou Zhang, \"Robust Part-Based Hand Gesture Recognition Using Kinect Sensor\", <em>TMM</em>, 2013.","title":"Robust Part-Based Hand Gesture Recognition Using Kinect Sensor","context":[{"sec":"sec1","text":" The approach using Finger-Earth Mover's Distance (FEMD) operates in real time, and it is able to distinguish the various poses efficiently and accurately [2].","part":"1"}],"links":{"documentLink":"/document/6470686","pdfSize":"1596KB"},"refType":"biblio","id":"ref2"},{"order":"3","text":"<em>NYU Hand Pose Dataset</em>,  [online]  Available: http://cims.nyu.edu/~tompson/NYU_Hand_Pose_Dataset.htm.","title":"NYU Hand Pose Dataset","context":[{"sec":"sec1","text":" This paper shows the effectiveness of the modified network on the state-of-the-arts hand gesture dataset [3].","part":"1"},{"sec":"sec2","text":" For this purpose the dataset from NYU Hand Pose Dataset v2 [3] is popular in aspect of the number of hand poses and articulations.","part":"1"}],"refType":"biblio","id":"ref3"},{"order":"4","text":"A. Krizhevsky, I. Sutskever and G. Hinton, \"ImageNet classication with deep convolutional neural networks\", <em>NIPS</em>, 2012.","title":"ImageNet classication with deep convolutional neural networks","context":[{"sec":"sec1","text":" One of the CNNs called AlexNet [4] is surprisingly highly accurate in the ImageNet LSVRC-2012 contest [5].","part":"1"},{"sec":"sec1","text":"Alexnet [4] structure.","part":"1"}],"refType":"biblio","id":"ref4"},{"order":"5","text":"A. Berg, J. Deng and L. Fei-Fei, <em>Large scale visual recognition challenge</em>, 2012,  [online]  Available: www.image-net.org/challenges.","title":"Large scale visual recognition challenge","context":[{"sec":"sec1","text":" One of the CNNs called AlexNet [4] is surprisingly highly accurate in the ImageNet LSVRC-2012 contest [5].","part":"1"}],"refType":"biblio","id":"ref5"},{"order":"6","text":"<em>Deep Learing Framework by the BVLC.</em>,  [online]  Available: http://caffe.berkeleyvision.org/.","title":"Deep Learing Framework by the BVLC.","context":[{"sec":"sec2","text":" All networks were trained using caffe library [6] and Nvidia DIGITS [7].","part":"1"}],"refType":"biblio","id":"ref6"},{"order":"7","text":"<em>Interactive Deep Learning GPU Training System</em>,  [online]  Available: https://developer.nvidia.com/digits.","title":"Interactive Deep Learning GPU Training System","context":[{"sec":"sec2","text":" All networks were trained using caffe library [6] and Nvidia DIGITS [7].","part":"1"}],"refType":"biblio","id":"ref7"}],"articleNumber":"7625742","issueLink":"/xpl/tocresult.jsp?isnumber=null","formulaStrippedArticleTitle":"Depth-based hand gesture recognition using convolutional neural networks","publisher":"IEEE","htmlAbstractLink":"/document/7625742/","displayDocTitle":"Depth-based hand gesture recognition using convolutional neural networks","isConference":true,"htmlLink":"/document/7625742/","isStaticHtml":true,"xploreDocumentType":"Conference Publication","isDynamicHtml":true,"articleId":"7625742","openAccessFlag":"F","title":"Depth-based hand gesture recognition using convolutional neural networks","contentTypeDisplay":"Conferences","mlTime":"PT0.072405S","lastupdate":"2021-12-11","contentType":"conferences","definitions":"false","publicationNumber":"7589475"},{"_id":7625747,"references":[{"order":"1","text":"Ryan Kiros, Ruslan Salakhutdinov and Rich Zemel, \"Multimodal neural language models\", <em>Proceedings of the 31st InternationalConference on Machine Learning (ICML-14)</em>, pp. 595-603, 2014.","title":"Multimodal neural language models","context":[{"sec":"sec1","text":"Automatically generating caption from an image [1] is one of the primary goal of computer vision.","part":"1"}],"refType":"biblio","id":"ref1"},{"order":"2","text":"Alex Krizhevsky, Ilya Sutskever and Geoffrey E Hinton, \"Imagenet classification with deep convolutional neural networks\", <em>Advances in neural information processing systems</em>, pp. 1097-1105, 2012.","title":"Imagenet classification with deep convolutional neural networks","context":[{"sec":"sec1","text":" Image caption generation area have recieved attentions since the developement of Deep Learning [2].","part":"1"}],"refType":"biblio","id":"ref2"},{"order":"3","text":"Oriol Vinyals, Alexander Toshev, Samy Bengio and Dumitru Erhan, \"Show and tell: A neural image caption generator\", <em>Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition</em>, pp. 3156-3164, 2015.","title":"Show and tell: A neural image caption generator","context":[{"sec":"sec1","text":" Especially, a model called Show and Tell [3] which use Long-short term memory (LSTM) [4] is one of the most remarkable model in neural caption generation model.","part":"1"}],"links":{"pdfSize":"402KB"},"refType":"biblio","id":"ref3"},{"order":"4","text":"Sepp Hochreiter and J\u00fcrgen Schmidhuber, \"Long short-term memory\", <em>Neural computation</em>, vol. 9, no. 8, pp. 1735-1780, 1997.","title":"Long short-term memory","context":[{"sec":"sec1","text":" Especially, a model called Show and Tell [3] which use Long-short term memory (LSTM) [4] is one of the most remarkable model in neural caption generation model.","part":"1"},{"sec":"sec2","text":"Our model employed encoder-decoder pipeline. we used CNN as a image encoder, and LSTM [4] as a sentence generator.","part":"1"}],"links":{"crossRefLink":"https://doi.org/10.1162/neco.1997.9.8.1735","pdfSize":"237KB"},"refType":"biblio","id":"ref4"},{"order":"5","text":"Xu Jia, Efstratios Gavves, Basura Fernando and Tinne Tuytelaars, \"Guiding long-short term memory for image caption generation\", 2015.","title":"Guiding long-short term memory for image caption generation","context":[{"sec":"sec2b","text":" Therefore, we employed guided LSTM (gLSTM) model [5] instead of LSTM.","part":"1"}],"links":{"documentLink":"/document/7410634","pdfSize":"779KB"},"refType":"biblio","id":"ref5"},{"order":"6","text":"Donggeun Yoo, Sunggyun Park, Joon-Young Lee and In Kweon, \"Multiscale pyramid pooling for deep convolutional representation\", <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</em>, pp. 71-80, 2015.","title":"Multiscale pyramid pooling for deep convolutional representation","context":[{"sec":"sec3","text":" Therefore, we propose a method to fine-tune CNN on sentences dataset, and employed multi-scale pyramid pooling [6] for aggragating the activations from CNN into Fisher vector.","part":"1"},{"sec":"sec3b","text":" Finally, the vectors are pooled to a finale vector with MPP [6].","part":"1"}],"refType":"biblio","id":"ref6"}],"articleNumber":"7625747","issueLink":"/xpl/tocresult.jsp?isnumber=null","formulaStrippedArticleTitle":"Sentence learning on deep convolutional networks for image Caption Generation","publisher":"IEEE","htmlAbstractLink":"/document/7625747/","isStaticHtml":true,"isConference":true,"htmlLink":"/document/7625747/","xploreDocumentType":"Conference Publication","isDynamicHtml":true,"displayDocTitle":"Sentence learning on deep convolutional networks for image Caption Generation","articleId":"7625747","openAccessFlag":"F","title":"Sentence learning on deep convolutional networks for image Caption Generation","contentTypeDisplay":"Conferences","mlTime":"PT0.040393S","lastupdate":"2021-12-11","contentType":"conferences","definitions":"false","publicationNumber":"7589475"}]